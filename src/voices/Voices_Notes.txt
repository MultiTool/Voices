
What next?

Any iplayable's playerhead should treat that playable as if its time begins at 0, and ends at Duration.  So rename getfinaltime to Duration_G() or Get_Duration. 

Should any playable know absolute time?  we can leave that for later.

Are we going to support time scaling/compressing?  Only for rythm, therefore not for pitch.  
So in the future every playerhead can ref an absoluterealtime clock, but we will cross that bridge when we get to it.  
Or rather we might have a Tempo coordinate, but not yet.  It can be derived from absoluterealtime.  

EndTime -= this.RealTimeAbsolute;// ???   // first, have to convert EndTime to local time offset. 
// EndTime -= this.TimeLoc;//.RealTimeAbsolute;// ???   // first, have to convert EndTime to local time offset. 


Next, fuse VoiceBase with Voice, because IPlayable is now the common ancestor element. 

the last song started may not be the last one playing. we need to scan the whole tree at compose time. 
so what about a collection of all subsongs sorted by end time?  that certainly allows easy measure of chorus duration.
does it help in any other way?  well if I treesearch in to the list I can find every subsong that ends after the current range begins. 
also every one that ends *before* the current range begins. 

Could we have a ghost tree?  Even though the whole tree is a directed graph where one limb can belong to many branches, maybe a whole real non-duplicate tree can point to all the branches.
How?  subsongs can't commit to any one location, so the ghost tree must point to all the subsongs. Will it know what they are?  
Each player will be born referencing both its subsong and its fully-connected tree node. 

The main pain here is that we may have come up with a better idea, and need to rewrite everything.  

Advantages of ghost tree: dirty bits can bubble up from children. maybe we don't need player heads anymore?  with single-instance tree we can just traverse the tree.
and so, each subsong spawns its tree part, and the tree part gets added to the real tree.  

mostly we are just editing treeparts, and then they ref to their own subsongs to edit the main details. 
WARNING: more than one treepart can ref the same subsong, so edits may conflict. treepart now serves dual purpose of an edit locator and a player. 
treeparts therefore keep current play state. each treepart will have drawing code too?  

treepart edit features:
find all parents. 
when tree is clicked, go through treeparts to find subsong in question.  edit song, bubble changes upward. 

really 90% of the program is about the stateful tree, just some parameters are stored in the subsongs.  

treepart.Render_To()

do subsongs have lists of sub-subsongs?  on the principle of multiple locations they must. 
their treeparts must also have lists of sub-treeparts that each point to each subsong.  Add a subsong to a subsong list, or remove it, and the parent treepart must also be updated. 

each treepart parent will need both a list of its treepart children, AND a list of all NowPlaying. 
treepart.Start() will wipe all the sub-treepart play states, or rather call all of their Start() fns.  
StartPlay()

Every time a SubSong is added to the tree, 
1. it spawns a treepart which points back to the SubSong, 
2. the treepart is added to the ghost tree, 
3. all of the SubSong's children also spawn self-pointing treeparts which are then added to the parent treepart's list.  

What if we remove a child from a treepart when editing?  then we remove that child from the SubSong. 
How to sync?  the treepart child's MyPhrase pointer tells us the ID of the SubSong child, but how do we look it up?  SubSong has a hash table?  
And SubSong can NEVER be edited except through treepart, because SubSong does not know where all of its personal treeparts are and cannot update them. 

Well all of SubSong's children are always sorted by time, as are its treepart's, so a treesearch will find either. 

All files can be saved as just the subsongs.  The true tree can be regenerated each time we load it.  Just traverse the directed graph and make duplicates whenever you visit a node twice.  

SkeleTree
ArbolEsquelito
Scaffold 
ScaffoldNode

What about OffsetBoxes?  do we still need those?  The SkeleTree can absorb them when it is generated.  Every treepart has its own coords built in, offset from its parent.  
But, every SubSong parent still needs to own a list of OffsetBoxes in order to place its children, who individually cannot know their own locations.  OffsetBox is still needed. 

SkeleTree is more of a memory hog, as the whole thing persists between renders.  

Oy how does it map to loops?  It can/must explode for vines, but maybe loops can be special?  All loop children are just one SubSong.  The last child to start is the last to end, and any edits are mirrored across all loop children.  

Strategy for change:
Back up everything done so far. 
Rename project to VectorMusic? 
Convert all playerhead types to TreePart or SkeleTree or SkeleNode or ScaffoldNode.  
SkeleNodes with children get lists of SkeleNode children.  

No longer spawn any new sub-players during render time.  Just iterate through all skele-children, restart each with Start() and then Render_To() as needed.  
When a child is done take it off the NowPlaying list.  

Loops do look painful. Think this through well.  

Hit stack will keep parent pointers and will also bubble up the edit flag.  Is hitstack or skeletree better for multiselect?  
with multiselect, in either case hitstack or skeletree must return a hit tree.  or a hit group/list or something.  

what about separating graphics from core code?  separating audio is easy, everything is buffered to wave arrays. 
graphics could be supported by child classes.  or each code meat defines an interface of callbacks the graphics can pass.  but that'd be a huge job, to duplicate the Java graphics API.  
well each class could define a simple(x,y, etc.) interface and the graphic layer could define complicated delegates and pass them as callbacks. 

/*
 Big picture, all the good effects depend on containers.  transposition, looping, bending, etc.

 How to do this neatly?

 voice spawns player
 phrase spawns player

 player runs, midwifes new players from phrase's children. 
 maybe the player should just get OffsetBox's coordinates separately and apply them to the playerhead children. 

 problem is OffsetBox is generic, can't see its type of child. 

 ergo, each phrase would be better off having its own unique list of pointers to children phrases. 
 but, need to associate transformation with each child.  

 double collections, one for boxes and one for children?

 or special OffsetBoxes, each owned by each type of phrase?  that is each phrase owns its own type of OffsetBox, or each phrase owns its children's type of OffsetBox? 
 better if each phrase owns its own type of OffsetBox. if a parent knows its children, then it will know their OffsetBoxes.  

 still weird.  but if every phrase type owns its OffsetBox, then each phrase can expand the number of coordinates that can manipulate the child.  

 what about octaverate/bending 'coords'?  kinda like coords but not displayed as such. 

 so: each parent player has free control over its children players, including arbitrary new dimensions of coordinates. 

 does bending count as a coordinate?  only if you want to bend the whole phrase. not very useful, do not include. 

 */


ripped from public static class Singer implements IOffsetBox {// Cantante
/* ********************************************************************************* */
@Override public double TimeLoc_g() {
  return Inherited_Time;
}
@Override public void TimeLoc_s(double value) {
  Inherited_Time = value;
}
@Override public double OctaveLoc_g() {
  return Inherited_Octave;
}
@Override public void OctaveLoc_s(double value) {
  Inherited_Octave = value;
}
@Override public double LoudnessLoc_g() {
  return Inherited_Loudness;
}
@Override public void LoudnessFactor_s(double value) {
  Inherited_Loudness = value;
}
@Override public ISonglet GetContent() {
  return null;
}
@Override public double MapTime(double ParentTime) {
  return this.Inherited_Time + ChildTime;
}
@Override public double UnMapTime(double ChildTime) {
  return Inherited_Octave;
}
@Override public Singer Spawn_Singer() {
  return Inherited_Octave;
}

Skip_To
int Last_Song_Dex = MySonglet.SubSongs.size() - 1;
OffsetBox cb = MySonglet.SubSongs.get(Current_Dex);// repeat until cb start time > EndTime
while (cb.TimeOrg < EndTime) {// first find new voices in this time range and add them to pool
  Singer singer = cb.Spawn_Singer();// SHOULD EndTime BE INCLUSIVE???
  singer.Inherit(this);
  this.NowPlaying.add(singer);
  singer.Start();
  if (Current_Dex >= Last_Song_Dex) {
    break;
  }
  Current_Dex++;
  cb = MySonglet.SubSongs.get(Current_Dex);
}

Render_To
int Last_Song_Dex = MySonglet.SubSongs.size() - 1;
OffsetBox cb = MySonglet.SubSongs.get(this.Current_Dex);// repeat until cb start time > EndTime
while (cb.TimeOrg <= Final_Start) {// first find new songlets in this time range and add them to pool
	Singer singer = cb.Spawn_Singer();// SHOULD EndTime BE INCLUSIVE???
	singer.Inherit(this);
	this.NowPlaying.add(singer);
	singer.Start();
	if (Current_Dex >= Last_Song_Dex) {
	  break;
	}
	this.Current_Dex++;
	cb = MySonglet.SubSongs.get(this.Current_Dex);
}


Next step:
test composing and rendering in project - working
test chords in project - working
  test deep overdubs - working 
  long complicated (random?) voices, - working with transpose
add audio support --next!!
make looper - working
drone sample player
fx: reverb, looper, vibrato, flanger, distortion

2^(1/12) = 1.0594630943592952645618252949463

*voces - el clic esta arreglado 
* output to wav - HECHO 
* maxamp - calc maxamp, update_maxamp - my dificil 
* fix sub-sample time alignment 
* biased white noise - ruido blanco con sesgo 
* voz de muestras 
* quita player_head 
* ModBox - container that splines loudness and pitch. buena para doblar acordes. 
* mas mus - may require gui to compose well, so next we need a tiny sample repeater, for realtime user bending. 

this.addMouseListener(new java.awt.event.MouseAdapter() {
  @Override public void mouseClicked(java.awt.event.MouseEvent evt) {
    System.out.println("mouseClicked");
  }
  @Override public void mouseEntered(java.awt.event.MouseEvent evt) {
    System.out.println("mouseEntered");
  }
  @Override public void mouseExited(java.awt.event.MouseEvent evt) {
    System.out.println("mouseExited");
  }
  @Override public void mousePressed(java.awt.event.MouseEvent evt) {
    System.out.println("mousePressed");
  }
  @Override public void mouseReleased(java.awt.event.MouseEvent evt) {
    System.out.println("mouseReleased");
  }
});

/*
Junkyard

ln(2) = 0.69314718 = 0.69314718055994530941723212145818

next?
long composition? 
graphics?
serialize and save/load? 
moving frame of reference?
vibrato effect?
loop effect? - need this
audio output? - need this, or at the very least save as raw file
voice type made of sample loops? - stretch goal

how vibrato?  Render_To_Bent(EndTime, EndOctave);
could just add the parent OctaveRate to our own, for the whole child render() span 

Render_To(){
double ParentOctaveOffset, ParentOctaveRate;
this.ParentPlayer.CurrentOctaveOffset;
this.ParentPlayer.CurrentOctaveRate;
}
static double Frequency_Integral_Bent_Octave(double slope, double ybase, double xval) {// http://www.quickmath.com   bent note math
double frequency_from_octave_integral = Math.pow(2.0, (ybase + slope * xval)) / (slope * Math.log(2.0));// returns the number of cycles since T0, assuming linear change to octave.
return frequency_from_octave_integral;
}

********************************************************************************* 
double SineGenerator(double time, double frequency, int sampleRate) {// http://stackoverflow.com/questions/8566938/how-to-properly-bend-a-note-in-an-audio-synthesis-application
return Math.sin(time += (frequency * 2 * Math.PI) / sampleRate);
}

so is every OffsetBox also an fxbox? and/or a container? 

OffsetBoxes were created so that a single instance of a voice would not carry its own offset coords everywhere it was reparented, or double-parented. 
but, a voice could be double-parented to an fxbox that had no coordinates of its own. (eventually you need a parent with coordinates though. 
you're always 0,0 from the inside of any parent that does not contain your OffsetBoxes. 

so should every voice spawn a OffsetBox to be attached to something?  doesn't seem like always. 
should I make my own OffsetBox if I am a voice?  

*/

Every IDrawable will have a bounding box, and every Drawing_Context will also have a bounding box. 
Drawing will always be called from the top, and the bounding box will define what to draw. 

Ugliness issues:
Every ISonglet will also have to be an IDrawable because all a parent knows about its children is that they are ISonglets. 
  Therefore, if a parent draws its children it will need access to their Draw_Me() functions.
OffsetBoxes will need scale transforms back to screen as well as translation offsets.  Audio isn't scalable (yet, maybe ever) but graphics must map to pixels. 
Could OffsetBoxes be the owners of all bounding boxes?  CPoints don't have offset boxes, but they can fake it, just handle their own bounding boxes and nothing else. 
If OffsetBoxes own bounding boxes, could they also be all the drawables? All OffsetBoxes know their ISonglets well. 
Every drawable has to pass its personal space transform to the Drawing_Context as it passes through. 
So Draw_Me becomes Draw_Content, more or less? 
In any case, whenever a Drawing_Context object passes through Draw_Me, it must remap to local coordinates. 
A Songlet does not point to the offsetbox it needs for this remapping, so either 
1. pass the offsetbox to its songlet's Draw_Me, or
2. perform the remap *before* we invoke the Draw_Me, or
3. give offsetbox the a Draw_Me function and it will have everything. 
if 3 then the offset box will have all of the IDrawable stuff to do.
Any issues with Songlets having and updating their own boundingboxes? 
OffsetBoxes are destined to contain two transforms: audio and graphics both. Maybe each has an AudMapTime, AudUnMapTime, and GraphicsMapTime, GraphicsUnMapTime ? or just AudMap(), AudUnMap() all coordinates? could offsetbox contain 2 instances of XForm class, one audio and one graphic? 
OffsetBoxes are good IDrawables because they already have coordinates, and what else?  Less clutter for Songlets?  

In this world, each OffsetBox has a Draw_Me(spacecontext) that it can override, and internally it can ref the songlet's custom Draw_Me(spacecontext) or whatever else. 
IDrawable could just have a Draw_Me, but it would still be synonymous with ISonglet. Ah, but not. Both IOffsetBox and ISonglet would share IDrawable. 
IOffsetBox would have all the UpdateBounds, GetBounds etc. 
If offset boxes own all the bounds, then they might have redundant bounds when multiple boxes own the same songlet. 
Yeah but well if we do a full recurse to update stuff, we will hit the same songlets twice anyway. 
for any updateguts, every songlet must have an update timestamp. if the timestamp is older than the current launch of updateguts, we delve in. if equal (or younger? never happens) then we skip that one. 
maybe then every songlet owns a boundingbox along with other guts, but the offsetboxes are the ones that do the updating? 
each songlet has 1. an update timestamp, and 2. a refcount. 

I like the idea of giving every offsetbox two personalities, one for graphics and one for sound. 

http://stackoverflow.com/questions/11163925/drawing-your-own-buffered-image-on-frame
BufferedImage off_Image = new BufferedImage(100, 50, BufferedImage.TYPE_INT_ARGB);
Graphics2D g2 = off_Image.createGraphics();

Graphics g = whatever;
BufferedImage bufferedImage;
g.drawImage(bufferedImage, 0, 0, WIDTH, HEIGHT, null);

private Rectangle2D rect = new Rectangle2D.Float();
ellipse.setFrame(x, y, ew, eh);
g2.setClip(ellipse);


to do:
Create LoopBox Draw_Me(). - done
Rename ChorusBox to GroupBox everywhere. - done
Put playing and drawing in separate threads. - done
More zoomed-in octave scale. - done
GroupBox Draw_Me needs to draw its own vine spine. Draw it behind its children. - done, touch it up more. 
Test live audio on faster machines. - done, TOO MUCH CLICKING, seek fix. 
Fix graphic clipping to work right. - done
Clean: Make ISonglet inherit IDrawable and remove redundant code. - done
Clean: Get rid of IOffsetBox.  - done
Clean: Big code cleanup. Consolidate all weird testing code into one place. - done
Put grid in background, seconds by octaves. - done
*** Fix bounds bug where covering origin of main branch hides everything, and bounds width is too short too.  - done
MemLeaks: Make IDeleteable interface and apply to *everything* to get ready for C++ port. - done
MemLeaks: All IDeleteable have a global creation counter and a global deletion counter. 
MemLeaks: Add refcounting for eventual serialization, IDeleteable, and C++ port. 
Import TunePad colors and alpha tricks. - working, more to do.
SubRange: Update and test all Skip_To.  
SubRange: Let user draw box on screen to trigger play within range. 
LoopBox graphics - mayabe an arc, Ellipse2D.Double?  Or a very rounded rectangle behind each unit cell? Put handles on the rectangle and change Delay. 
Add Zoom, ZoomX, and ZoomY. ctrl or shift or alt-scrollwheel?  Also add panning. 
On load, zoom to object bounds. 
** Start grabbing mouse clicks and creating hit stacks. !!! 
Add moving cursor during play. 
Draw to buffer and draw buffer as a strip to main image. 
Add 'excitement' double to drawing context, and animate drawings as we play. 
Customize colors for each songlet! 
Widgets! SFGUI? 
(Someday) create a sample_voice type. http://soundbible.com/37-Chain-Saw.html 
Add ISerializable for saving and loading! 
Do we need update_guts timestamps?
Separate out the drawing/graphics layer. 
Undo/Redo?  probably need IClonable and or ICopyable, like ISerializable.  Clone invokes Copy, and copy just copies all guts. 
Optimize voice polygon graphic clipping. 
Control points of a songlet should only show up when the songlet is selected. 
Line widths should scale with zooming. 
FX box, with sigmoid clipping, reverb etc. 





